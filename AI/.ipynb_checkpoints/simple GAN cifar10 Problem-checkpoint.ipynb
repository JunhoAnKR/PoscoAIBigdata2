{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(train_data, train_label), (test_data, test_label) = cifar10.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "ax1.imshow(sample_data);\n",
    "# ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: (100, 32, 32, 3)\n",
      "D: (100, 16, 16, 64)\n",
      "D: (100, 8, 8, 128)\n",
      "D: (100, 4, 4, 256)\n",
      "D: (100, 2, 2, 512)\n",
      "D: (100, 2048)\n",
      "D: (100, 2048)\n",
      "D: (100, 1)\n",
      "------------------------\n",
      "G: (100, 128)\n",
      "G: (100, 2048)\n",
      "G: (100, 2, 2, 512)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 8, 8, 128)\n",
      "G: (100, 16, 16, 64)\n",
      "G: (100, 32, 32, 3)\n",
      "------------------------\n",
      "D: (100, 32, 32, 3)\n",
      "D: (100, 16, 16, 64)\n",
      "D: (100, 8, 8, 128)\n",
      "D: (100, 4, 4, 256)\n",
      "D: (100, 2, 2, 512)\n",
      "D: (100, 2048)\n",
      "D: (100, 2048)\n",
      "D: (100, 1)\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f65d477bad6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;31m# Make optimization op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;31m# To update the generator and the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # in_channel: input channel dimension\n",
    "    # w_shape: shape of weight matrix\n",
    "    # b_shape: shape of bias vector\n",
    "    in_channel = inputs.get_shape().as_list()[1]\n",
    "    w_shape = [in_channel, out_channel]\n",
    "    b_shape = [out_channel]\n",
    "\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        weights = tf.get_variable('weights', shape=w_shape,\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        biases = tf.get_variable('biases', shape=b_shape,\n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "        fc = tf.matmul(inputs, weights)\n",
    "        fc = tf.nn.bias_add(fc, biases)\n",
    "\n",
    "        return fc\n",
    "\n",
    "def conv2d(input_, output_dim, k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02, name=\"conv2d\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n",
    "              initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
    "        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n",
    "\n",
    "        return conv\n",
    "\n",
    "def bn(x, is_training, scope, axis=-1):\n",
    "    return tf.layers.batch_normalization(x, epsilon = 1e-5, momentum = 0.9, training = is_training, name = scope, axis=axis) # add axis=1\n",
    "\n",
    "def linear(input_, output_size, scope=None, stddev=0.02, bias_start=0.0, with_w=False):\n",
    "    shape = input_.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n",
    "                 tf.random_normal_initializer(stddev=stddev))\n",
    "        bias = tf.get_variable(\"bias\", [output_size],\n",
    "        initializer=tf.constant_initializer(bias_start))\n",
    "        if with_w:\n",
    "            return tf.matmul(input_, matrix) + bias, matrix, bias\n",
    "        else:\n",
    "            return tf.matmul(input_, matrix) + bias\n",
    "\n",
    "def deconv2d(input_, output_shape, k_h=5, k_w=5, d_h=2, d_w=2, name=\"deconv2d\", stddev=0.02, with_w=False):\n",
    "    with tf.variable_scope(name):\n",
    "        # filter : [height, width, output_channels, in_channels]\n",
    "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n",
    "                            initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "\n",
    "        try:\n",
    "            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        # Support for verisons of TensorFlow before 0.7.0\n",
    "        except AttributeError:\n",
    "            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape, strides=[1, d_h, d_w, 1])\n",
    "\n",
    "        biases = tf.get_variable('biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
    "        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n",
    "\n",
    "        if with_w:\n",
    "            return deconv, w, biases\n",
    "        else:\n",
    "            return deconv\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "        \n",
    "def discriminator(x, reuse=None, is_training=True):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 32, 32, 3]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "#             if self.dataset_name == 'cifar10':\n",
    "        if True:\n",
    "            print(\"D:\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            net = lrelu(conv2d(x, 64, 5, 5, 2, 2, name='d_conv1'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 128, 5, 5, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 256, 5, 5, 2, 2, name='d_conv3'), is_training=is_training, scope='d_bn3'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = lrelu(bn(conv2d(net, 512, 5, 5, 2, 2, name='d_conv4'), is_training=is_training, scope='d_bn4'))\n",
    "            print(\"D:\",net.get_shape())\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out_logit = linear(net, 1, scope='d_fc5')\n",
    "            print(\"D:\",net.get_shape())\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "        else: # mnist / fashion mnist\n",
    "            #print(x.get_shape())\n",
    "            net = lrelu(conv2d(x, 64, 4, 4, 2, 2, name='d_conv1'))\n",
    "            net = lrelu(bn(conv2d(net, 128, 4, 4, 2, 2, name='d_conv2'), is_training=is_training, scope='d_bn2'))\n",
    "            net = tf.reshape(net, [batch_size, -1])\n",
    "            net = lrelu(bn(linear(net, 1024, scope='d_fc3'), is_training=is_training, scope='d_bn3'))\n",
    "            out_logit = linear(net, 1, scope='d_fc4')\n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "\n",
    "        return out\n",
    "\n",
    "def generator(z, is_training=True):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        h_size = 32\n",
    "        h_size_2 = 16\n",
    "        h_size_4 = 8\n",
    "        h_size_8 = 4\n",
    "        h_size_16 = 2\n",
    "\n",
    "        print(\"G:\",z.get_shape())\n",
    "        net = linear(z, 512*h_size_16*h_size_16, scope='g_fc1')\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(tf.reshape(net, [batch_size, h_size_16, h_size_16, 512]),is_training=is_training, scope='g_bn1')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_8, h_size_8, 256], 5, 5, 2, 2, name='g_dc2'),is_training=is_training, scope='g_bn2')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_4, h_size_4, 128], 5, 5, 2, 2, name='g_dc3'),is_training=is_training, scope='g_bn3')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        net = tf.nn.relu(\n",
    "            bn(deconv2d(net, [batch_size, h_size_2, h_size_2, 64], 5, 5, 2, 2, name='g_dc4'),is_training=is_training, scope='g_bn4')\n",
    "            )\n",
    "        print(\"G:\",net.get_shape())\n",
    "        out = tf.nn.sigmoid(\n",
    "            deconv2d(net, [batch_size, 32, 32, 3], 5, 5, 2, 2, name='g_dc5')\n",
    "            )\n",
    "        print(\"G:\",out.get_shape())\n",
    "        print(\"------------------------\")\n",
    "    return out\n",
    "\n",
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_fake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = -(tf.reduce_mean(tf.log(D_real+eps)) + tf.reduce_mean(tf.log(1-D_fake+eps)))\n",
    "    G_loss = -tf.reduce_mean(tf.log(D_fake+eps))\n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lrD = 1e-3\n",
    "lrG = 1e-4\n",
    "beta1 = 0.5\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 32, 32, 3], name='input_x')\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = tf.random_uniform((batch_size, z_dim), -1., 1., name='latent_z')\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "D_real = discriminator(x, reuse=False)\n",
    "# Build generator\n",
    "G = generator(z)\n",
    "# Build discriminator where input data is generated image G\n",
    "D_fake = discriminator(G, reuse=True)\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "D_loss, G_loss = get_loss(D_real, D_fake)\n",
    "# Make optimization op\n",
    "optD = tf.train.AdamOptimizer(lrD, beta1=beta1)\n",
    "optG = tf.train.AdamOptimizer(lrG, beta1=beta1)\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "G_params = [param for param in tf.trainable_variables()\n",
    "            if 'generator' in param.name]\n",
    "D_params = [param for param in tf.trainable_variables()\n",
    "            if 'discriminator' in param.name]\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = optD.minimize(D_loss, var_list=D_params)\n",
    "G_train = optG.minimize(G_loss, var_list=G_params)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        #summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        #train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled)\n",
    "#             plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "https://github.com/4thgen/DCGAN-CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
