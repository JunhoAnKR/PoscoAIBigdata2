{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets.cifar100 import load_data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "(train_data, train_label), (test_data, test_label) = load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "sample_data = train_data[100]\n",
    "plt.imshow(sample_data, cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19],\n",
       "       [29],\n",
       "       [ 0],\n",
       "       ...,\n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [73]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 label을 모델예측값과 비교하기위해 변환\n",
    "train_label = train_label.sum(axis=1)\n",
    "test_label = test_label.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 29,  0, ...,  3,  7, 73])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "batch_size = 200\n",
    "num_display = 50\n",
    "\n",
    "# resnet layer define\n",
    "# filter수가 변하지 않게 resinet layer를 쌓는 경우는 구현했으며,\n",
    "# 논문처럼 filter수를 변하게 하면서 구현하고 싶어 코드를 참고했습니다.\n",
    "\n",
    "def residual_block(X, filters, strd):\n",
    "    ## 논문에서 filter수를 2배 늘릴 때마다 map size를 1/2배 하는것을 구현하고 싶었습니다.\n",
    "    ## 여기부터\n",
    "    if strd: # padding 해줌으로써 차원을 맞춰줌\n",
    "        stride = 2\n",
    "        pool1 = tf.layers.max_pooling2d(X, strides=2, pool_size=[1,1])\n",
    "        pad1 = tf.pad(pool1, [[0,0], [0,0], [0,0], [int(filters/4),int(filters/4)]])\n",
    "        shortcut = pad1\n",
    "    else:\n",
    "        stride = 1 # 차원이 변하지 않기 때문에 그대로 shortcut을 가져옴\n",
    "        shortcut = X\n",
    "        \n",
    "    ## 여기까지를 웹사이트를 참고.\n",
    "    \n",
    "    outs = tf.layers.conv2d(X, filters, 3, padding='same',strides=stride) \n",
    "    outs = tf.layers.batch_normalization(outs)\n",
    "    outs = tf.nn.relu(outs)\n",
    "\n",
    "    outs = tf.layers.conv2d(outs, filters, 3, padding='same',strides=1)\n",
    "    outs = tf.layers.batch_normalization(outs)        \n",
    "\n",
    "   \n",
    "    outs = tf.nn.relu(shortcut+ outs)\n",
    "    \n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet layers--\n",
    "X = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
    "by = tf.placeholder(tf.int32)\n",
    "\n",
    "\n",
    "first = tf.layers.conv2d(X, 64, 3, padding=\"SAME\") # (None, 32, 32, 64)\n",
    "first = tf.layers.batch_normalization(first)\n",
    "first = tf.nn.relu(first)\n",
    "# 논문에서는 pooling하여 사이즈를 1/2배 하지만 본 데이터는 32*32짜리 이미지 데이터라 pooling은 너무 많은 데이터 손실이 생길 것이라\n",
    "# 판단하여 하지 않았습니다. ( 논문과 다른 점 )\n",
    "\n",
    "rb1 = residual_block(first, 64, False) # (None, 32, 32, 64)\n",
    "rb2 = residual_block(rb1, 64, False) # (None, 32, 32, 64)\n",
    "rb3 = residual_block(rb2, 64, False) # (None, 32, 32, 64)\n",
    "\n",
    "rb4 = residual_block(rb3, 128, True) # (None, 16, 16, 128)\n",
    "rb5 = residual_block(rb4, 128, False)# (None, 16, 16, 128)\n",
    "rb6 = residual_block(rb5, 128, False)# (None, 16, 16, 128)\n",
    "\n",
    "rb7 = residual_block(rb6, 256, True) # (None, 8, 8, 256)\n",
    "rb8 = residual_block(rb7, 256, False)# (None, 8, 8, 256)\n",
    "rb9 = residual_block(rb8, 256, False)# (None, 8, 8, 256)\n",
    "\n",
    "rb10 = residual_block(rb9, 512, True) # (None, 4, 4, 512)\n",
    "rb11 = residual_block(rb10, 512, False)# (None, 4, 4, 512)\n",
    "rb12 = residual_block(rb11, 512, False)# (None, 4, 4, 512)\n",
    "\n",
    "\n",
    "outs = tf.layers.average_pooling2d(rb12, 2, 2)\n",
    "outs = tf.reshape(outs, (-1, outs.shape[1]*outs.shape[2]*outs.shape[3]))\n",
    "outs = tf.layers.dense(outs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = tf.one_hot(by, 100)\n",
    "    \n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=outs, \n",
    "                                                  labels=one_hot)\n",
    "loss = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "preds = tf.cast(tf.argmax(tf.nn.softmax(outs), axis=1), tf.int32)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(by, preds), tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration 1\n",
      "loss 4.6017 acc 0.0150\n",
      "loss 4.5049 acc 0.0250\n",
      "loss 4.2931 acc 0.0600\n",
      "loss 4.0734 acc 0.0600\n",
      "loss 4.0365 acc 0.1350\n",
      "Current iteration 2\n",
      "loss 4.0863 acc 0.0900\n",
      "loss 3.9850 acc 0.1050\n",
      "loss 3.9895 acc 0.0900\n",
      "loss 3.8765 acc 0.1400\n",
      "loss 3.5641 acc 0.1600\n",
      "Current iteration 3\n",
      "loss 3.7054 acc 0.1300\n",
      "loss 3.5392 acc 0.1750\n",
      "loss 3.4136 acc 0.1750\n",
      "loss 3.3408 acc 0.2150\n",
      "loss 3.3375 acc 0.1900\n",
      "Current iteration 4\n",
      "loss 3.1384 acc 0.2550\n",
      "loss 3.1459 acc 0.2500\n",
      "loss 3.2064 acc 0.2300\n",
      "loss 3.0076 acc 0.2650\n",
      "loss 3.0155 acc 0.2750\n",
      "Current iteration 5\n",
      "loss 2.9681 acc 0.3000\n",
      "loss 2.9609 acc 0.2400\n",
      "loss 2.8333 acc 0.2450\n",
      "loss 2.8710 acc 0.2700\n",
      "loss 3.0099 acc 0.2400\n",
      "Current iteration 6\n",
      "loss 2.5985 acc 0.3600\n",
      "loss 2.7085 acc 0.3250\n",
      "loss 2.5884 acc 0.3100\n",
      "loss 2.6165 acc 0.3100\n",
      "loss 2.6847 acc 0.2850\n",
      "Current iteration 7\n",
      "loss 2.3242 acc 0.3450\n",
      "loss 2.5296 acc 0.3550\n",
      "loss 2.4884 acc 0.3500\n",
      "loss 2.3375 acc 0.4100\n",
      "loss 2.4266 acc 0.3900\n",
      "Current iteration 8\n",
      "loss 2.1009 acc 0.4650\n",
      "loss 2.0518 acc 0.4800\n",
      "loss 2.1091 acc 0.4800\n",
      "loss 1.9974 acc 0.4850\n",
      "loss 2.4181 acc 0.3800\n",
      "Current iteration 9\n",
      "loss 1.6709 acc 0.5350\n",
      "loss 1.7336 acc 0.5000\n",
      "loss 1.9618 acc 0.5000\n",
      "loss 1.9566 acc 0.4900\n",
      "loss 1.8701 acc 0.5100\n",
      "Current iteration 10\n",
      "loss 1.3093 acc 0.6200\n",
      "loss 1.2655 acc 0.6550\n",
      "loss 1.3000 acc 0.6450\n",
      "loss 1.5128 acc 0.5900\n",
      "loss 1.3631 acc 0.6500\n",
      "Current iteration 11\n",
      "loss 1.2047 acc 0.6500\n",
      "loss 0.9685 acc 0.6950\n",
      "loss 1.1431 acc 0.6650\n",
      "loss 1.1803 acc 0.6500\n",
      "loss 1.1112 acc 0.6700\n",
      "Current iteration 12\n",
      "loss 0.5065 acc 0.8700\n",
      "loss 0.8025 acc 0.7500\n",
      "loss 0.6823 acc 0.7900\n",
      "loss 1.0710 acc 0.7150\n",
      "loss 0.8789 acc 0.7400\n",
      "Current iteration 13\n",
      "loss 0.4202 acc 0.8500\n",
      "loss 0.5661 acc 0.8200\n",
      "loss 0.5254 acc 0.8600\n",
      "loss 0.7236 acc 0.7800\n",
      "loss 0.8356 acc 0.7300\n",
      "Current iteration 14\n",
      "loss 0.5606 acc 0.8600\n",
      "loss 0.4074 acc 0.8750\n",
      "loss 0.6748 acc 0.8200\n",
      "loss 0.6551 acc 0.8250\n",
      "loss 0.6278 acc 0.7850\n",
      "Current iteration 15\n",
      "loss 0.3342 acc 0.9050\n",
      "loss 0.4040 acc 0.8800\n",
      "loss 0.4661 acc 0.8350\n",
      "loss 0.4899 acc 0.8550\n",
      "loss 0.5119 acc 0.8500\n",
      "Current iteration 16\n",
      "loss 0.3898 acc 0.8950\n",
      "loss 0.2960 acc 0.8900\n",
      "loss 0.4598 acc 0.8250\n",
      "loss 0.5693 acc 0.8050\n",
      "loss 0.6325 acc 0.7900\n",
      "Current iteration 17\n",
      "loss 0.2902 acc 0.9400\n",
      "loss 0.3695 acc 0.8950\n",
      "loss 0.3472 acc 0.9000\n",
      "loss 0.2494 acc 0.9300\n",
      "loss 0.4896 acc 0.8550\n",
      "Current iteration 18\n",
      "loss 0.2005 acc 0.9450\n",
      "loss 0.2611 acc 0.9200\n",
      "loss 0.2549 acc 0.9150\n",
      "loss 0.3302 acc 0.8800\n",
      "loss 0.3055 acc 0.9100\n",
      "Current iteration 19\n",
      "loss 0.1882 acc 0.9450\n",
      "loss 0.2828 acc 0.9000\n",
      "loss 0.2909 acc 0.8950\n",
      "loss 0.2850 acc 0.9350\n",
      "loss 0.3950 acc 0.8550\n",
      "Current iteration 20\n",
      "loss 0.2228 acc 0.9050\n",
      "loss 0.3359 acc 0.9050\n",
      "loss 0.3519 acc 0.8750\n",
      "loss 0.2276 acc 0.9250\n",
      "loss 0.4078 acc 0.8800\n",
      "TEST: loss 5.4899 acc 0.2913\n"
     ]
    }
   ],
   "source": [
    "# index를 random하게 가져오기 위해 batch index를 suffle # ref.Hanson-ml book\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        \n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#     writer = tf.summary.FileWriter('./logs/a')\n",
    "#     writer.add_graph(sess.graph)\n",
    "#     writer.close()\n",
    "    for ind_epoch in range(0, num_epochs):\n",
    "        print('Current iteration {}'.format(ind_epoch + 1))\n",
    "        batch_cnt = 0\n",
    "        for batch_X, batch_by in shuffle_batch(train_data, train_label, batch_size):\n",
    "            batch_cnt += 1\n",
    "            _, cur_loss, cur_acc = sess.run(\n",
    "                [opt, loss, acc],\n",
    "                feed_dict={X: batch_X, by: batch_by})\n",
    "            if batch_cnt % num_display == 0:\n",
    "                print('loss {0:.4f} acc {1:.4f}'.format(cur_loss, cur_acc))\n",
    "    cur_acc_all = 0.0\n",
    "    cur_loss_all = 0.0\n",
    "    for ind_ in range(0, 10):\n",
    "        cur_loss, cur_acc = sess.run(\n",
    "                    [loss, acc],\n",
    "                    feed_dict={X: test_data[ind_*1000:(ind_+1)*1000], \n",
    "                               by: test_label[ind_*1000:(ind_+1)*1000]})\n",
    "        cur_loss_all += cur_loss\n",
    "        cur_acc_all += cur_acc\n",
    "    print('TEST: loss {0:.4f} acc {1:.4f}'.format(cur_loss_all / 10.0, \n",
    "                                                  cur_acc_all / 10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
